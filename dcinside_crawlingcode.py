import requests
from bs4 import BeautifulSoup
import time

headers = {
    "User-Agent": "Mozilla/5.0"
}

# í¬ë¡¤ë§ ëŒ€ìƒ ê°¤ëŸ¬ë¦¬ ID ì…ë ¥
GALLERY_ID = "baseball_new"  # ì˜ˆ: ì•¼êµ¬ ê°¤ëŸ¬ë¦¬

# ìˆ˜ì§‘í•  ê²Œì‹œê¸€ í˜ì´ì§€ ìˆ˜ (í•œ í˜ì´ì§€ë‹¹ ì•½ 20ê°œ ê¸€)
MAX_PAGES = 170

output_file = "dc_output.txt"

def get_post_urls(page):
    url = f"https://gall.dcinside.com/board/lists/?id={GALLERY_ID}&page={page}"
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")

    urls = []
    rows = soup.select("tr.ub-content")

    for row in rows:
        a_tag = row.select_one("td.gall_tit a")
        if a_tag and "href" in a_tag.attrs:
            href = a_tag["href"]
            if "view" in href:
                full_url = "https://gall.dcinside.com" + href
                urls.append(full_url)

    return urls

def get_post_content_and_comments(url):
    try:
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")

        # ê²Œì‹œê¸€ ë³¸ë¬¸
        content = soup.select_one("div.write_div").get_text(strip=True)

        # ëŒ“ê¸€
        comment_tags = soup.select("div.inner_text")
        comments = [c.get_text(strip=True) for c in comment_tags]

        return content, comments
    except Exception as e:
        print(f"Error: {e}")
        return "", []

# ğŸ”½ ë³¸ë¬¸ê³¼ ëŒ“ê¸€ ì €ì¥ ì‹œì‘
with open(output_file, "w", encoding="utf-8") as f:
    for page in range(1, MAX_PAGES + 1):
        print(f"í˜ì´ì§€ {page} ì²˜ë¦¬ ì¤‘...")
        post_urls = get_post_urls(page)
        for post_url in post_urls:
            print(f"  â–¶ {post_url}")
            content, comments = get_post_content_and_comments(post_url)

            if content:
                f.write("[ë³¸ë¬¸]\n")
                f.write(content + "\n")

            for comment in comments:
                f.write("[ëŒ“ê¸€]\n")
                f.write(comment + "\n")

            f.write("-----\n")  # êµ¬ë¶„ì„ 

            time.sleep(0.5)  # ì„œë²„ ë¶€í•˜ ë°©ì§€