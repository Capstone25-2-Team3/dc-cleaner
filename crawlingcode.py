import requests
from bs4 import BeautifulSoup
import time

headers = {
    "User-Agent": "Mozilla/5.0"
}

# âœ… ë§ˆì´ë„ˆ ê°¤ëŸ¬ë¦¬ ID
GALLERY_ID = "kica"
BASE_URL = f"https://gall.dcinside.com/mgallery/board/lists/?id={GALLERY_ID}"
POST_BASE = "https://gall.dcinside.com"

# âœ… ìˆ˜ì§‘í•  í˜ì´ì§€ ìˆ˜
MAX_PAGES = 100
output_file = f"dc_{GALLERY_ID}_sentences.tsv"  # âœ íƒ­ìœ¼ë¡œ êµ¬ë¶„ëœ í…ìŠ¤íŠ¸ íŒŒì¼

def get_post_urls(page):
    url = f"{BASE_URL}&page={page}"
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")

    urls = []
    rows = soup.select("tr.ub-content")

    for row in rows:
        a_tag = row.select_one("td.gall_tit a")
        if a_tag and "href" in a_tag.attrs:
            href = a_tag["href"]
            if "view" in href:
                full_url = POST_BASE + href
                urls.append(full_url)

    return urls

def get_post_content_and_comments(url):
    try:
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")

        # ê²Œì‹œê¸€ ë³¸ë¬¸
        content_tag = soup.select_one("div.write_div")
        content = content_tag.get_text(strip=True) if content_tag else ""

        # ëŒ“ê¸€
        comment_tags = soup.select("div.inner_text")
        comments = [c.get_text(strip=True) for c in comment_tags]

        return content, comments
    except Exception as e:
        print(f"âŒ Error: {e}")
        return "", []

# ğŸ”½ ì €ì¥
with open(output_file, "w", encoding="utf-8") as f:
    for page in range(1, MAX_PAGES + 1):
        print(f"ğŸ“„ í˜ì´ì§€ {page} ì²˜ë¦¬ ì¤‘...")
        post_urls = get_post_urls(page)

        for post_url in post_urls:
            print(f"  â–¶ {post_url}")
            content, comments = get_post_content_and_comments(post_url)

            if content:
                f.write(f"{post_url}\t{content}\n")
            for comment in comments:
                f.write(f"{post_url}\t{comment}\n")

            time.sleep(0.5)